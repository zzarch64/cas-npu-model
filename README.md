# CAS-NPU: PyTorch è‡ªå®šä¹‰ NPU è®¾å¤‡æ‰©å±•

<div align="center">

![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?style=flat&logo=pytorch)
![Python](https://img.shields.io/badge/Python-3.8+-3776ab?style=flat&logo=python)
![C++](https://img.shields.io/badge/C++-17-00599c?style=flat&logo=cplusplus)
![License](https://img.shields.io/badge/License-MIT-green?style=flat)

**åŸºäº PyTorch PrivateUse1 æœºåˆ¶å®ç°çš„è‡ªå®šä¹‰ NPU è®¾å¤‡æ‰©å±•**

[å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) â€¢ [æ·»åŠ ç®—å­](#æ·»åŠ ç®—å­) â€¢ [è¿è¡Œç½‘ç»œ](#è¿è¡Œç½‘ç»œ) â€¢ [è°ƒè¯•å·¥å…·](#è°ƒè¯•å·¥å…·) â€¢ [å¼€å‘æ–‡æ¡£](DEVLOG.md)

</div>

---

## ğŸ“– é¡¹ç›®ç®€ä»‹

CAS-NPU æ˜¯ä¸€ä¸ªä½¿ç”¨ PyTorch çš„ `PrivateUse1` æœºåˆ¶å®ç°çš„è‡ªå®šä¹‰è®¾å¤‡æ‰©å±•æ¡†æ¶ã€‚å®ƒæä¾›äº†ä¸€å¥—å®Œæ•´çš„ NPU åç«¯å®ç°ï¼Œæ”¯æŒï¼š

- âœ… **å®Œæ•´çš„è®¾å¤‡æŠ½è±¡**ï¼šå†…å­˜ç®¡ç†ã€è®¾å¤‡åˆ‡æ¢ã€æµåŒæ­¥
- âœ… **æ¸è¿›å¼ç®—å­å¼€å‘**ï¼šNPU åŸç”Ÿå®ç° + CPU Fallback æ··åˆæ¨¡å¼
- âœ… **å¤šåç«¯æ”¯æŒ**ï¼šcmodelï¼ˆè°ƒè¯•ï¼‰/ FPGA / ASICï¼ˆç”Ÿäº§ï¼‰
- âœ… **LLM æ¨ç†éªŒè¯**ï¼šå·²é€šè¿‡ Qwen 0.5B å®Œæ•´å‰å‘ä¼ æ’­æµ‹è¯•

### å½“å‰çŠ¶æ€

| åŠŸèƒ½ | çŠ¶æ€ | ä¼˜å…ˆçº§ | è¯´æ˜ |
|-----|------|-------|------|
| LeNet Forward | âœ… å®Œæˆ | - | CPU vs NPU è¾“å‡ºä¸€è‡´ |
| Qwen 0.5B Forward | âœ… å®Œæˆ | - | å®Œæ•´æ¨ç†æµç¨‹ |
| **LoRA Finetune** | ğŸš§ å¾…å¼€å‘ | ğŸ”´ P0 | æ”¯æŒ Qwen æ¨¡å‹è®­ç»ƒï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰ |
| CModel ç‰©ç†å†…å­˜æŠ½è±¡ | ğŸš§ å¾…å¼€å‘ | ğŸŸ¡ P1 | ä» CPU è™šæ‹Ÿåœ°å€è¿ç§»åˆ° NPU ç‰©ç†åœ°å€æ¨¡å‹ |
| RTL Model (Verilator) | ğŸš§ å¾…å¼€å‘ | ğŸŸ¡ P1 | åŸºäº Verilator çš„ RTL ä»¿çœŸåç«¯ |
| ç¼–è¯‘åç«¯åˆ‡æ¢ | ğŸš§ å¾…å¼€å‘ | ğŸŸ¡ P1 | CMake/setup.py ç¼–è¯‘é€‰é¡¹æ”¯æŒå¤šåç«¯ |
| Runtime æ¶æ„åˆ†å±‚ | ğŸš§ å¾…å¼€å‘ | ğŸŸ¢ P2 | æŠ½è±¡ç»Ÿä¸€æ¥å£ï¼Œåˆ†ç¦» cmodel/rtlmodel/fpga/asic |

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python API Layer                                               â”‚
â”‚  cas_npu/__init__.py - è®¾å¤‡ç®¡ç†ã€åç«¯æ³¨å†Œ                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PyTorch Backend Layer (backend/)                               â”‚
â”‚  â”œâ”€ cas_npu_ops.cpp        - ç®—å­å®ç° (NPUåŸç”Ÿ / CPU Fallback)   â”‚
â”‚  â”œâ”€ cas_npu_allocator.cpp  - è®¾å¤‡å†…å­˜åˆ†é…å™¨                      â”‚
â”‚  â”œâ”€ cas_npu_guard.cpp      - DeviceGuard å®ç°                   â”‚
â”‚  â”œâ”€ cas_npu_hooks.cpp      - PrivateUse1 Hooks                  â”‚
â”‚  â””â”€ cas_npu_module.cpp     - Python ç»‘å®š (pybind11)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Runtime API Layer (runtime/cas_npu_runtime.h)                  â”‚
â”‚  â”œâ”€ å†…å­˜ç®¡ç†ï¼šcasNpuMalloc, casNpuFree, casNpuMemcpy            â”‚
â”‚  â””â”€ è®¡ç®—ç®—å­ï¼šcasNpuMatMul, casNpuAddTensor, ...                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Hardware Implementation Layer                                   â”‚
â”‚  â”œâ”€ runtime/cmodel/  - CPU æ¨¡æ‹Ÿå®ç°ï¼ˆå¼€å‘è°ƒè¯•ï¼‰                   â”‚
â”‚  â”œâ”€ runtime/fpga/    - FPGA ç¡¬ä»¶å®ç°                            â”‚
â”‚  â””â”€ runtime/asic/    - æœªæ¥ ASIC èŠ¯ç‰‡å®ç°                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç›®å½•ç»“æ„

```
npu_cas_extension/
â”œâ”€â”€ backend/                          # PyTorch åç«¯é›†æˆå±‚
â”‚   â”œâ”€â”€ cas_npu_allocator.h/cpp       # è®¾å¤‡å†…å­˜åˆ†é…å™¨
â”‚   â”œâ”€â”€ cas_npu_guard.h/cpp           # DeviceGuard å®ç°
â”‚   â”œâ”€â”€ cas_npu_hooks.h/cpp           # PrivateUse1 Hooks
â”‚   â”œâ”€â”€ cas_npu_ops.cpp               # ç®—å­å®ç°ï¼ˆæ ¸å¿ƒæ–‡ä»¶ï¼‰
â”‚   â”œâ”€â”€ cas_npu_module.cpp            # Python ç»‘å®š
â”‚   â””â”€â”€ cas_npu_custom_ops_example.cpp # è‡ªå®šä¹‰ç®—å­ç¤ºä¾‹
â”œâ”€â”€ runtime/                          # Runtime å±‚
â”‚   â”œâ”€â”€ cas_npu_runtime.h             # Runtime API å®šä¹‰
â”‚   â”œâ”€â”€ cas_npu_debug.h               # è°ƒè¯•ç³»ç»Ÿ
â”‚   â”œâ”€â”€ cmodel/simulator.cpp          # C æ¨¡å‹æ¨¡æ‹Ÿå™¨
â”‚   â””â”€â”€ fpga/simulator.cpp            # FPGA å®ç°
â”œâ”€â”€ cas_npu/                          # Python åŒ…
â”‚   â”œâ”€â”€ __init__.py                   # åŒ…åˆå§‹åŒ– & è®¾å¤‡æ³¨å†Œ
â”‚   â””â”€â”€ debug.py                      # Python è°ƒè¯•æ¥å£
â”œâ”€â”€ test/                             # æµ‹è¯•æ–‡ä»¶
â”‚   â”œâ”€â”€ test_cas_npu.py               # åŸºç¡€åŠŸèƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_lenet.py                 # LeNet ç½‘ç»œæµ‹è¯•
â”‚   â”œâ”€â”€ test_qwen0.5B.py              # Qwen æ¨¡å‹æµ‹è¯•
â”‚   â””â”€â”€ test_custom_ops.py            # è‡ªå®šä¹‰ç®—å­æµ‹è¯•
â”œâ”€â”€ setup.py                          # æ„å»ºè„šæœ¬
â”œâ”€â”€ build_and_test.sh                 # ä¸€é”®æ„å»ºæµ‹è¯•è„šæœ¬
â”œâ”€â”€ DEVLOG.md                         # å¼€å‘æ—¥å¿—ï¼ˆè¯¦ç»†è®¾è®¡æ–‡æ¡£ï¼‰
â””â”€â”€ README.md                         # æœ¬æ–‡æ¡£
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- PyTorch 2.0+
- C++17 å…¼å®¹ç¼–è¯‘å™¨ï¼ˆGCC 7+ / Clang 5+ï¼‰

### ç¼–è¯‘å®‰è£…

```bash
# æ–¹æ³•1ï¼šä¸€é”®æ„å»ºå¹¶æµ‹è¯•
chmod +x build_and_test.sh
./build_and_test.sh

# æ–¹æ³•2ï¼šæ‰‹åŠ¨æ„å»º
python setup.py build_ext --inplace

# æ–¹æ³•3ï¼šä½¿ç”¨ FPGA åç«¯æ„å»º
CAS_NPU_IMPL=fpga python setup.py build_ext --inplace
```

### éªŒè¯å®‰è£…

```bash
# è¿è¡ŒåŸºç¡€æµ‹è¯•
python test/test_cas_npu.py

# è¿è¡Œç½‘ç»œæµ‹è¯•
python test/test_lenet.py
```

### åŸºç¡€ä½¿ç”¨

```python
import torch
import cas_npu  # è‡ªåŠ¨æ³¨å†Œåç«¯

# æ£€æŸ¥è®¾å¤‡
print(f"CAS-NPU available: {torch.cas_npu.is_available()}")
print(f"Device count: {torch.cas_npu.device_count()}")

# åˆ›å»ºè®¾å¤‡ä¸Šçš„ Tensor
device = torch.device("cas_npu:0")
a = torch.randn(3, 3, device=device)
b = torch.randn(3, 3, device=device)

# æ‰§è¡Œè®¡ç®—
c = a + b  # ä½¿ç”¨ NPU åŸç”Ÿ add å®ç°
d = torch.mm(a, b)  # ä½¿ç”¨ NPU åŸç”Ÿ mm å®ç°

# ç»“æœè½¬å› CPU
print(c.cpu())
```

---

## ğŸ”§ æ·»åŠ ç®—å­

CAS-NPU æ”¯æŒä¸¤ç§ç®—å­å®ç°æ–¹å¼ï¼Œå¯æ ¹æ®å¼€å‘é˜¶æ®µçµæ´»é€‰æ‹©ï¼š

### æ–¹å¼ä¸€ï¼šNPU åŸç”Ÿå®ç°ï¼ˆé«˜æ€§èƒ½ï¼‰

ç›´æ¥åœ¨ NPU ä¸Šæ‰§è¡Œï¼Œæ—  CPU å¾€è¿”ï¼Œé€‚ç”¨äºé«˜é¢‘ç®—å­ã€‚

#### æ­¥éª¤ 1ï¼šåœ¨ Runtime å±‚å£°æ˜ API

åœ¨ `runtime/cas_npu_runtime.h` ä¸­æ·»åŠ å‡½æ•°å£°æ˜ï¼š

```cpp
// ä¾‹ï¼šå®ç° rsqrt ç®—å­
CasNpuError casNpuRsqrt(
    float* output,
    const float* input,
    size_t num_elements);
```

#### æ­¥éª¤ 2ï¼šå®ç° Runtime å‡½æ•°

åœ¨ `runtime/cmodel/simulator.cpp` ä¸­å®ç°ï¼š

```cpp
CasNpuError casNpuRsqrt(
    float* output,
    const float* input,
    size_t num_elements) {
    for (size_t i = 0; i < num_elements; ++i) {
        output[i] = 1.0f / std::sqrt(input[i]);
    }
    return CAS_NPU_SUCCESS;
}
```

#### æ­¥éª¤ 3ï¼šæ³¨å†Œ PyTorch ç®—å­

åœ¨ `backend/cas_npu_ops.cpp` ä¸­æ³¨å†Œï¼š

```cpp
at::Tensor cas_npu_rsqrt(const at::Tensor& self) {
    auto output = at::empty_like(self);
    
    auto err = cas_npu::casNpuRsqrt(
        output.data_ptr<float>(),
        self.data_ptr<float>(),
        self.numel()
    );
    TORCH_CHECK(err == cas_npu::CAS_NPU_SUCCESS, "NPU rsqrt failed");
    
    return output;
}

TORCH_LIBRARY_IMPL(aten, PrivateUse1, m) {
    m.impl("rsqrt", &cas_npu_rsqrt);
}
```

### æ–¹å¼äºŒï¼šCPU Fallbackï¼ˆå¿«é€Ÿå¼€å‘ï¼‰

åˆ©ç”¨ PyTorch çš„ CPU å®ç°ï¼Œè‡ªåŠ¨å¤„ç†æ•°æ®ä¼ è¾“ã€‚é€‚ç”¨äºï¼š
- å¼€å‘åˆæœŸå¿«é€ŸéªŒè¯
- ä½é¢‘ç®—å­
- å¤æ‚ç®—å­çš„ä¸´æ—¶æ–¹æ¡ˆ

#### ä½¿ç”¨ç»Ÿä¸€ cpu_fallback å‡½æ•°

```cpp
// backend/cas_npu_ops.cpp ä¸­å·²å®ç°é€šç”¨ cpu_fallback
TORCH_LIBRARY_IMPL(aten, PrivateUse1, m) {
    m.impl("rsqrt", &cpu_fallback<&at::native::rsqrt>);
    m.impl("pow.Tensor_Scalar", &cpu_fallback<&at::native::pow>);
    // ... æ›´å¤šç®—å­
}
```

#### æ‰‹åŠ¨å®ç° Fallbackï¼ˆéœ€è¦ç‰¹æ®Šå¤„ç†æ—¶ï¼‰

```cpp
at::Tensor cas_npu_some_op(const at::Tensor& self) {
    // 1. æ‹·è´åˆ° CPU
    at::Tensor self_cpu = self.to(at::kCPU);
    
    // 2. åœ¨ CPU ä¸Šæ‰§è¡Œ
    at::Tensor result_cpu = at::some_op(self_cpu);
    
    // 3. æ‹·è´å›è®¾å¤‡
    return result_cpu.to(self.device());
}
```

### æ–¹å¼ä¸‰ï¼šè‡ªå®šä¹‰å‘½åç©ºé—´ç®—å­

æ³¨å†Œ PyTorch ä¸­ä¸å­˜åœ¨çš„å…¨æ–°ç®—å­ï¼š

```cpp
// å®šä¹‰ Schema
TORCH_LIBRARY(cas_npu, m) {
    m.def("custom_quantize(Tensor input, float scale, int zero_point) -> Tensor");
}

// å®ç°ç®—å­
at::Tensor cas_npu_custom_quantize(const at::Tensor& input, double scale, int64_t zero_point) {
    // ... å®ç°
}

// æ³¨å†Œåˆ°è®¾å¤‡
TORCH_LIBRARY_IMPL(cas_npu, PrivateUse1, m) {
    m.impl("custom_quantize", &cas_npu_custom_quantize);
}
```

Python è°ƒç”¨ï¼š

```python
output = torch.ops.cas_npu.custom_quantize(input_tensor, 0.1, 0)
```

---

## ğŸ§  è¿è¡Œç½‘ç»œ

### åŸºç¡€ï¼šç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡

```python
import torch
import torch.nn as nn
import cas_npu

device = torch.device('cas_npu:0')

# æ–¹æ³•1ï¼šåˆ›å»ºåç§»åŠ¨
model = MyModel()
model = model.to(device)

# æ–¹æ³•2ï¼šç›´æ¥åœ¨è®¾å¤‡ä¸Šåˆ›å»º
with torch.device(device):
    model = MyModel()

# å‡†å¤‡è¾“å…¥
input_data = torch.randn(batch_size, ...).to(device)

# æ¨ç†
with torch.no_grad():
    output = model(input_data)
```

### ç¤ºä¾‹ï¼šè¿è¡Œ LeNet

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import cas_npu

class LeNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
    
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), 2)
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.flatten(1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        return self.fc3(x)

# è¿è¡Œæ¨ç†
device = torch.device('cas_npu:0')
model = LeNet().to(device)
x = torch.randn(4, 1, 28, 28).to(device)

with torch.no_grad():
    output = model(x)
    print(output.cpu())
```

### ç¤ºä¾‹ï¼šè¿è¡Œ Qwen 0.5B

```python
import torch
import cas_npu
from transformers import AutoModel, AutoTokenizer

device = torch.device('cas_npu:0')

# åŠ è½½æ¨¡å‹
model_name = "Qwen/Qwen2.5-0.5B"
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModel.from_pretrained(
    model_name,
    trust_remote_code=True,
    dtype=torch.float32,
)

# ç§»åŠ¨åˆ° NPU
model = model.to(device)
model.eval()

# æ¨ç†
text = "Hello, how are you?"
inputs = tokenizer(text, return_tensors="pt")
input_ids = inputs["input_ids"].to(device)

with torch.no_grad():
    outputs = model(input_ids)
    hidden_states = outputs.last_hidden_state
    print(f"Output shape: {hidden_states.shape}")
```

---

## ğŸ› è°ƒè¯•å·¥å…·

### ç¯å¢ƒå˜é‡æ§åˆ¶

```bash
# å¯ç”¨è°ƒè¯•æ‰“å°
CAS_NPU_DEBUG=1 python your_script.py

# è®¾ç½®è¯¦ç»†ç¨‹åº¦ (1-3)
CAS_NPU_DEBUG_LEVEL=2 python your_script.py
```

| Level | æ˜¾ç¤ºå†…å®¹ |
|-------|---------|
| 1 | ä»…ç®—å­æ‰§è¡Œä¿¡æ¯ |
| 2 | ç®—å­æ‰§è¡Œ + æ•°æ®ä¼ è¾“ï¼ˆé»˜è®¤ï¼‰ |
| 3 | å…¨éƒ¨ä¿¡æ¯ï¼ˆå« Runtime å±‚ï¼‰ |

### Python API æ§åˆ¶

```python
import cas_npu.debug as debug

# å¯ç”¨/ç¦ç”¨
debug.enable(level=2)
debug.disable()

# ä¸´æ—¶è°ƒè¯•æ¨¡å¼
with debug.debug_mode(level=3):
    output = model(input)
```

### è¾“å‡ºæ ¼å¼è¯´æ˜

```
[NPU]      ç»¿è‰² - NPU åŸç”Ÿå®ç°ï¼ˆé«˜æ€§èƒ½ï¼‰
[CPUâ†â†’NPU] é»„è‰² - æ˜¾å¼ CPU Fallback
[VIEW]     é’è‰² - View æ“ä½œï¼ˆä»…ä¿®æ”¹ metadataï¼‰
[CPU]      çº¢è‰² - çº¯ CPU Fallback
[COPY]     è“è‰² - æ•°æ®æ‹·è´æ“ä½œ

æ•°æ®ä¼ è¾“:
[Hâ†’D] - Host åˆ° Device
[Dâ†’H] - Device åˆ° Host
[Dâ†’D] - Device åˆ° Device
```

### ç¤ºä¾‹è¾“å‡º

```
[NPU] mm [128x768] @ [768x3072]
[CPUâ†â†’NPU] rsqrt [98304]
    â†³ [Dâ†’H] 384.00 KB
    â†³ [Hâ†’D] 384.00 KB
[VIEW] reshape
```

---

## ğŸ“Š ç®—å­æ”¯æŒçŠ¶æ€

### NPU åŸç”Ÿå®ç°ï¼ˆé«˜æ€§èƒ½ï¼‰

| ç®—å­ | Runtime API | ç”¨é€” |
|-----|-------------|------|
| `mm` | `casNpuMatMul` | Linear å±‚ã€æŠ•å½± |
| `bmm` | `casNpuBatchMatMul` | Attention è®¡ç®— |
| `add.Tensor` | `casNpuAddTensor` | æ®‹å·®è¿æ¥ |

### CPU Fallbackï¼ˆå¾…ä¼˜åŒ–ï¼‰

| ç±»åˆ« | ç®—å­ | ä¼˜å…ˆçº§ |
|-----|------|-------|
| RMSNorm | `rsqrt`, `pow`, `mean.dim` | ğŸ”´ é«˜ |
| æ¿€æ´»å‡½æ•° | `silu`, `relu` | ğŸ”´ é«˜ |
| Rotary Embedding | `cos`, `sin` | ğŸ”´ é«˜ |
| åŸºç¡€è¿ç®— | `mul.Tensor`, `div.Tensor` | ğŸŸ¡ ä¸­ |
| Attention | `softmax`, `scaled_dot_product_attention` | ğŸŸ¡ ä¸­ |

### View æ“ä½œï¼ˆé›¶å¼€é”€ï¼‰

`view`, `reshape`, `transpose`, `permute`, `unsqueeze`, `squeeze`, `expand`, `slice`, `select`, `as_strided`, `t`, `detach`

> è¯¦ç»†å¼€å‘è®¡åˆ’è¯·å‚è€ƒ [DEVLOG.md](DEVLOG.md)

---

## ğŸ—ºï¸ å¼€å‘è·¯çº¿å›¾

### ğŸš§ å¾…å¼€å‘åŠŸèƒ½ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰

#### 1. ğŸ”´ LoRA Finetune æ”¯æŒï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰

**é—®é¢˜**ï¼šå½“å‰ä»…æ”¯æŒæ¨ç†ï¼ˆå‰å‘ä¼ æ’­ï¼‰ï¼Œä¸æ”¯æŒè®­ç»ƒï¼ˆåå‘ä¼ æ’­ï¼‰ã€‚

**ç›®æ ‡**ï¼šåœ¨ CAS-NPU ä¸Šå®ç° Qwen 0.5B çš„ LoRA å¾®è°ƒï¼ŒéªŒè¯è®­ç»ƒæ”¯æŒã€‚

**éœ€è¦å®ç°çš„åŠŸèƒ½**ï¼š

| ç±»åˆ« | éœ€æ±‚ | ä¼˜å…ˆçº§ |
|-----|------|-------|
| Autograd æ”¯æŒ | å®ç° `backward()` ç›¸å…³ç®—å­ | ğŸ”´ P0 |
| æ¢¯åº¦è®¡ç®— | `mm` åå‘ã€`add` åå‘ç­‰ | ğŸ”´ P0 |
| ä¼˜åŒ–å™¨æ”¯æŒ | AdamW ç­‰ä¼˜åŒ–å™¨åœ¨è®¾å¤‡ä¸Šæ‰§è¡Œ | ğŸŸ¡ P1 |
| LoRA å±‚ | ä½ç§©é€‚é…å™¨çš„é«˜æ•ˆå®ç° | ğŸŸ¡ P1 |
| æ··åˆç²¾åº¦ | FP16/BF16 è®­ç»ƒæ”¯æŒ | ğŸŸ¢ P2 |

**å®ç°è·¯å¾„**ï¼š
1. å®ç°åŸºç¡€åå‘ä¼ æ’­ç®—å­ï¼ˆä» Fallback å¼€å§‹ï¼‰
2. éªŒè¯ç®€å•ç½‘ç»œï¼ˆå¦‚ LeNetï¼‰çš„è®­ç»ƒ
3. å®ç° LoRA ç›¸å…³ç®—å­çš„ NPU åŸç”Ÿç‰ˆæœ¬
4. å®Œæˆ Qwen LoRA å¾®è°ƒç«¯åˆ°ç«¯æµç¨‹

#### 2. CModel ç‰©ç†å†…å­˜æŠ½è±¡

**é—®é¢˜**ï¼šå½“å‰ CModel ç›´æ¥ä½¿ç”¨ CPU è™šæ‹Ÿåœ°å€ï¼ˆ`malloc`/`free`ï¼‰ï¼Œæ— æ³•çœŸå®æ¨¡æ‹Ÿ NPU çš„ç‰©ç†å†…å­˜è®¿é—®è¡Œä¸ºã€‚

**ç›®æ ‡**ï¼š
- ç»´æŠ¤ä¸€å¥—ç‹¬ç«‹çš„ NPU ç‰©ç†åœ°å€ç©ºé—´
- CModel é€šè¿‡ç‰©ç†åœ°å€è¿›è¡Œè®¿å­˜æ¨¡æ‹Ÿ
- ä¸ºåç»­ RTL Model å’Œç¡¬ä»¶å¯¹æ¥æ‰“å¥½åŸºç¡€

```
å½“å‰å®ç°ï¼ˆé—®é¢˜ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  casNpuMalloc() â”€â”€â–¶ CPU malloc() â”€â”€â–¶ è¿”å› CPU è™šæ‹Ÿåœ°å€       â”‚
â”‚  casNpuMemcpy() â”€â”€â–¶ CPU memcpy() â”€â”€â–¶ ç›´æ¥æ“ä½œ CPU å†…å­˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç›®æ ‡å®ç°ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NPU Physical Address Space (æ¨¡æ‹Ÿ)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  0x0000_0000 â”€â”¬â”€ Weight Memory Region               â”‚   â”‚
â”‚  â”‚               â”œâ”€ Activation Memory Region           â”‚   â”‚
â”‚  â”‚               â””â”€ ... (å¯é…ç½®å¸ƒå±€)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                 â”‚
â”‚  casNpuMalloc() â”€â”€â–¶ åˆ†é…ç‰©ç†åœ°å€ â”€â”€â–¶ è¿”å› NPU ç‰©ç†åœ°å€       â”‚
â”‚  casNpuMemcpy() â”€â”€â–¶ ç‰©ç†åœ°å€è½¬æ¢ â”€â”€â–¶ æ“ä½œæ¨¡æ‹Ÿ RAM            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3. RTL Model æ”¯æŒ (Verilator)

**ç›®æ ‡**ï¼šåŸºäº Verilator å°† NPU IP çš„ RTL ä»£ç å°è£…ä¸ºä»¿çœŸåç«¯ã€‚

**æ¶æ„è®¾è®¡**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Runtime API Layer                                              â”‚
â”‚  casNpuMatMul(), casNpuAddTensor(), ...                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  RTL Model Backend (runtime/rtlmodel/)                          â”‚
â”‚  â”œâ”€ verilator_wrapper.cpp    - Verilator ä»¿çœŸæ§åˆ¶               â”‚
â”‚  â”œâ”€ axi_driver.cpp           - AXI æ€»çº¿é©±åŠ¨                     â”‚
â”‚  â”œâ”€ command_packet.h         - æ•°æ®/å‘½ä»¤åŒ…å®šä¹‰                   â”‚
â”‚  â””â”€ ram_interface.cpp        - RAM æ¨¡å‹æ¥å£                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Verilator Generated Code                                       â”‚
â”‚  â”œâ”€ Vnpu_top.h               - NPU é¡¶å±‚æ¨¡å—                     â”‚
â”‚  â””â”€ Vnpu_top__ALL.a          - ç¼–è¯‘åçš„ä»¿çœŸåº“                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  NPU RTL Design                                                 â”‚
â”‚  â”œâ”€ npu_top.v                - é¡¶å±‚æ¨¡å— (AXI Slave)             â”‚
â”‚  â”œâ”€ matrix_engine.v          - çŸ©é˜µè®¡ç®—å•å…ƒ                     â”‚
â”‚  â””â”€ ...                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**AXI æ¥å£ä¸å‘½ä»¤åŒ…è®¾è®¡**ï¼š

```cpp
// å‘½ä»¤åŒ…æ ¼å¼ï¼ˆç¤ºä¾‹ï¼‰
struct NpuCommandPacket {
    uint32_t opcode;        // æ“ä½œç : MATMUL, ADD, MEMCPY, ...
    uint32_t src1_addr;     // æºåœ°å€1 (ç‰©ç†åœ°å€)
    uint32_t src2_addr;     // æºåœ°å€2 (ç‰©ç†åœ°å€)
    uint32_t dst_addr;      // ç›®æ ‡åœ°å€ (ç‰©ç†åœ°å€)
    uint32_t param[4];      // å‚æ•°: M, K, N, alpha, ...
};

// AXI é©±åŠ¨æ¥å£
class AxiDriver {
    void writeCommand(const NpuCommandPacket& cmd);
    void waitComplete();
    void readStatus(uint32_t* status);
};
```

#### 4. ç¼–è¯‘åç«¯åˆ‡æ¢æ”¯æŒ

**ç›®æ ‡**ï¼šé€šè¿‡ç¼–è¯‘é€‰é¡¹æ”¯æŒ CModelã€RTLModelã€FPGAã€ASIC åç«¯çš„åˆ‡æ¢ã€‚

**ç¼–è¯‘å‘½ä»¤**ï¼š

```bash
# CModel åç«¯ï¼ˆé»˜è®¤ï¼Œå¿«é€Ÿå¼€å‘è°ƒè¯•ï¼‰
python setup.py build_ext --inplace
# æˆ–
CAS_NPU_BACKEND=cmodel python setup.py build_ext --inplace

# RTL Model åç«¯ï¼ˆRTL ä»¿çœŸéªŒè¯ï¼‰
CAS_NPU_BACKEND=rtlmodel python setup.py build_ext --inplace

# FPGA åç«¯ï¼ˆç¡¬ä»¶éªŒè¯ï¼‰
CAS_NPU_BACKEND=fpga python setup.py build_ext --inplace

# ASIC åç«¯ï¼ˆèŠ¯ç‰‡é©±åŠ¨ï¼‰
CAS_NPU_BACKEND=asic python setup.py build_ext --inplace
```

**setup.py æ”¹è¿›**ï¼š

```python
# è¯»å–åç«¯é€‰æ‹©
backend = os.environ.get('CAS_NPU_BACKEND', 'cmodel')

# æ ¹æ®åç«¯é€‰æ‹©æºæ–‡ä»¶
backend_sources = {
    'cmodel':   ['runtime/cmodel/backend.cpp'],
    'rtlmodel': ['runtime/rtlmodel/backend.cpp', 
                 'runtime/rtlmodel/verilator_wrapper.cpp'],
    'fpga':     ['runtime/fpga/backend.cpp'],
    'asic':     ['runtime/asic/backend.cpp'],
}
```

#### 5. Runtime æ¶æ„é‡æ„

**é—®é¢˜**ï¼šå½“å‰ Runtime å±‚çš„æŠ½è±¡ä¸å¤Ÿæ¸…æ™°ï¼Œ`cas_npu_runtime.h` ä¸­çš„ API å£°æ˜ä¸å…·ä½“å®ç°è€¦åˆè¿‡ç´§ã€‚

**ç›®æ ‡æ¶æ„**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Runtime API Layer (runtime/cas_npu_runtime.h)                  â”‚
â”‚  â”œâ”€ ç»Ÿä¸€æ¥å£å®šä¹‰ï¼ˆçº¯è™šå‡½æ•° / å‡½æ•°æŒ‡é’ˆè¡¨ï¼‰                          â”‚
â”‚  â””â”€ åç«¯æ— å…³çš„é€šç”¨é€»è¾‘                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Backend Abstraction Layer (runtime/backend_interface.h)        â”‚
â”‚  â”œâ”€ CasNpuBackend æŠ½è±¡åŸºç±»                                      â”‚
â”‚  â””â”€ è¿è¡Œæ—¶åç«¯é€‰æ‹© & åŠ¨æ€åŠ è½½                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Concrete Implementations                                        â”‚
â”‚  â”œâ”€ runtime/cmodel/backend.cpp    - CPU æ¨¡æ‹Ÿï¼ˆç‰©ç†å†…å­˜æ¨¡å‹ï¼‰      â”‚
â”‚  â”œâ”€ runtime/rtlmodel/backend.cpp  - Verilator RTL ä»¿çœŸ          â”‚
â”‚  â”œâ”€ runtime/fpga/backend.cpp      - FPGA ç¡¬ä»¶é©±åŠ¨               â”‚
â”‚  â””â”€ runtime/asic/backend.cpp      - ASIC èŠ¯ç‰‡é©±åŠ¨               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é¢„æœŸæ”¶ç›Š**ï¼š
- æ¸…æ™°çš„æ¥å£æŠ½è±¡ï¼Œä¾¿äºæ·»åŠ æ–°åç«¯
- æ”¯æŒè¿è¡Œæ—¶åŠ¨æ€åˆ‡æ¢åç«¯ï¼ˆä¸éœ€è¦é‡æ–°ç¼–è¯‘ï¼‰
- æ›´å¥½çš„ä»£ç å¤ç”¨å’Œæµ‹è¯•éš”ç¦»

---

## ğŸ§ª æµ‹è¯•

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test/test_cas_npu.py

# LeNet ç½‘ç»œæµ‹è¯•
python test/test_lenet.py

# Qwen æ¨¡å‹æµ‹è¯•ï¼ˆéœ€è¦ transformersï¼‰
python test/test_qwen0.5B.py

# è‡ªå®šä¹‰ç®—å­æµ‹è¯•
python test/test_custom_ops.py

# å¸¦è°ƒè¯•è¾“å‡ºæµ‹è¯•
CAS_NPU_DEBUG_LEVEL=2 python test/test_lenet.py
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [PyTorch PrivateUse1 æ–‡æ¡£](https://pytorch.org/docs/stable/notes/extending.html)
- [PyTorch Dispatcher è¯¦è§£](http://blog.ezyang.com/2020/09/lets-talk-about-the-pytorch-dispatcher/)
- [OpenRegistration å®˜æ–¹ç¤ºä¾‹](https://github.com/pytorch/pytorch/tree/main/test/cpp_extensions/open_registration_extension)

---

## ğŸ“ License

MIT License
